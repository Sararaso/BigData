{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_Pima_Indians_Diabetes_SolutionSS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxtRPAVkZ5Po",
        "colab_type": "text"
      },
      "source": [
        "# Data \n",
        "\n",
        "The Pima Indians dataset is about the prediction of diabetes . This is a small dataset available from the UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes\n",
        "\n",
        "**Attribute Information:**\n",
        "\n",
        "1. Number of times pregnant\n",
        "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "3. Diastolic blood pressure (mm Hg)\n",
        "4. Triceps skin fold thickness (mm)\n",
        "5. 2-Hour serum insulin (mu U/ml)\n",
        "6. Body mass index (weight in kg/(height in m)^2)\n",
        "7. Diabetes pedigree function\n",
        "8. Age (years)\n",
        "9. Class variable (0 or 1) (diabetes mellitus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDxLkTlYZ5Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the data\n",
        "#!wget -O pima-indians-diabetes.csv https://gist.githubusercontent.com/ktisha/c21e73a1bd1700294ef790c56c8aec1f/raw/819b69b5736821ccee93d05b51de0510bea00294/pima-indians-diabetes.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaM1uublZ5Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!curl https://gist.githubusercontent.com/ktisha/c21e73a1bd1700294ef790c56c8aec1f/raw/819b69b5736821ccee93d05b51de0510bea00294/pima-indians-diabetes.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0lztVEJ_Z5Py",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "45fce72d-29be-4d5e-9d83-ca02050367d2"
      },
      "source": [
        "# check if the data is downloaded\n",
        "%ls -l"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 28\n",
            "-rw-r--r-- 1 root root 23628 Jun  5 06:51 pima-indians-diabetes.csv\n",
            "drwxr-xr-x 1 root root  4096 May 31 16:17 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrSIV5_UZ5P4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d512868-4f2e-4caa-c9fc-e6e99d8061c0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUK4VW1QZ5P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0zGhOpHZ5P9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmjrGhSsm3mY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83dcb396-15c2-43d1-d5a2-ab00a8665980"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBMIJdZLZ5QE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split dataset into input (X) and output (Y) variables\n",
        "# output is the last column\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "24uQ6MHJZ5QG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "514bb732-c87a-4d33-a72d-10a563d55ce8"
      },
      "source": [
        "# print the shape of x\n",
        "#\n",
        "X.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XHiTzXdeZ5QK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83bf534b-554a-4fa7-85a6-c030f8eb102a"
      },
      "source": [
        "# save to number of input dimensions in input_dim\n",
        "input_dim = len(X.shape)\n",
        "input_dim"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sM4wmguxZ5QN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "849740ef-bc13-433a-a626-34519abf284d"
      },
      "source": [
        "# shape of y\n",
        "y.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tE6NO4LYZ5QR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training and test sets\n",
        "# Test size should be 15%\n",
        "# The test and train set should be stratified\n",
        "# use a random state (for reproducability) of 42\n",
        "# TODO\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.15, stratify=y, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00sTZc8GZ5QZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de257e3f-d837-4380-faa1-94b02d92c86e"
      },
      "source": [
        "# shape of X_test\n",
        "# TODO\n",
        "X_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFdD-u4tZ5Qc",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-easCcbZ5Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Create Sequential model\n",
        "# 2. + 3. Add two hidden dense layers with 12 and 8 nodes. Both should have Relu activations \n",
        "# 4. Add a final output layer\n",
        "# Think about how many nodes the final output layer should have and what activation function is appropiate\n",
        "# TODO\n",
        "model = Sequential()\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbFB-igFZ5Qg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "bc48f8f9-1cef-4f42-b8b1-430254daa686"
      },
      "source": [
        "# Compile the model\n",
        "# Think about what loss function is appropiate\n",
        "# Use as the optimizer Adam\n",
        "# Track as an additional metric Accuracy\n",
        "# TODO\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h5BQ_0xZ5Qj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10305
        },
        "outputId": "29817dc9-99a5-48fe-d089-ed611e70ed30"
      },
      "source": [
        "# Fit the model\n",
        "#\n",
        "# Use 15% for Validation\n",
        "# Train for 300 epochs\n",
        "# User batch size = 10\n",
        "# Save the model fitting into the variable history\n",
        "# TODO\n",
        "history = model.fit(X, y, validation_split=0.15, epochs=300, batch_size=10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 652 samples, validate on 116 samples\n",
            "Epoch 1/300\n",
            "652/652 [==============================] - 1s 1ms/step - loss: 4.0396 - acc: 0.6549 - val_loss: 2.3912 - val_acc: 0.5259\n",
            "Epoch 2/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 1.1686 - acc: 0.5445 - val_loss: 0.8881 - val_acc: 0.5345\n",
            "Epoch 3/300\n",
            "652/652 [==============================] - 0s 126us/step - loss: 0.7982 - acc: 0.6273 - val_loss: 0.9685 - val_acc: 0.5862\n",
            "Epoch 4/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.7193 - acc: 0.6472 - val_loss: 0.9219 - val_acc: 0.6034\n",
            "Epoch 5/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.7077 - acc: 0.6580 - val_loss: 0.7225 - val_acc: 0.6121\n",
            "Epoch 6/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.6784 - acc: 0.6733 - val_loss: 0.7127 - val_acc: 0.6207\n",
            "Epoch 7/300\n",
            "652/652 [==============================] - 0s 131us/step - loss: 0.6685 - acc: 0.6810 - val_loss: 0.7119 - val_acc: 0.6466\n",
            "Epoch 8/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.6522 - acc: 0.7055 - val_loss: 0.6893 - val_acc: 0.6810\n",
            "Epoch 9/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.6133 - acc: 0.7117 - val_loss: 0.7192 - val_acc: 0.5776\n",
            "Epoch 10/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.6336 - acc: 0.6856 - val_loss: 0.6889 - val_acc: 0.6466\n",
            "Epoch 11/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.6148 - acc: 0.7040 - val_loss: 0.7133 - val_acc: 0.6379\n",
            "Epoch 12/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.6189 - acc: 0.7147 - val_loss: 0.7758 - val_acc: 0.6897\n",
            "Epoch 13/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.5964 - acc: 0.7117 - val_loss: 0.6830 - val_acc: 0.6466\n",
            "Epoch 14/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.5965 - acc: 0.7132 - val_loss: 0.6533 - val_acc: 0.6897\n",
            "Epoch 15/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.6143 - acc: 0.6917 - val_loss: 0.7215 - val_acc: 0.6466\n",
            "Epoch 16/300\n",
            "652/652 [==============================] - 0s 126us/step - loss: 0.6015 - acc: 0.7040 - val_loss: 0.6535 - val_acc: 0.6293\n",
            "Epoch 17/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.5880 - acc: 0.7193 - val_loss: 0.6521 - val_acc: 0.6293\n",
            "Epoch 18/300\n",
            "652/652 [==============================] - 0s 127us/step - loss: 0.6122 - acc: 0.6902 - val_loss: 0.8131 - val_acc: 0.6552\n",
            "Epoch 19/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5861 - acc: 0.7163 - val_loss: 0.6740 - val_acc: 0.5776\n",
            "Epoch 20/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.6049 - acc: 0.6994 - val_loss: 0.6913 - val_acc: 0.6121\n",
            "Epoch 21/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.5622 - acc: 0.7270 - val_loss: 0.6520 - val_acc: 0.7069\n",
            "Epoch 22/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.5607 - acc: 0.7224 - val_loss: 0.6995 - val_acc: 0.6466\n",
            "Epoch 23/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5579 - acc: 0.7316 - val_loss: 0.6687 - val_acc: 0.6897\n",
            "Epoch 24/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5595 - acc: 0.7086 - val_loss: 0.6656 - val_acc: 0.6379\n",
            "Epoch 25/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.5725 - acc: 0.7193 - val_loss: 0.6508 - val_acc: 0.6638\n",
            "Epoch 26/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5721 - acc: 0.7040 - val_loss: 0.6980 - val_acc: 0.6724\n",
            "Epoch 27/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5596 - acc: 0.7362 - val_loss: 0.6376 - val_acc: 0.6724\n",
            "Epoch 28/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5539 - acc: 0.7071 - val_loss: 0.6284 - val_acc: 0.6810\n",
            "Epoch 29/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5487 - acc: 0.7439 - val_loss: 0.6742 - val_acc: 0.6552\n",
            "Epoch 30/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5492 - acc: 0.7239 - val_loss: 0.6249 - val_acc: 0.7328\n",
            "Epoch 31/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.5403 - acc: 0.7239 - val_loss: 0.6428 - val_acc: 0.6724\n",
            "Epoch 32/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.5527 - acc: 0.7377 - val_loss: 0.7938 - val_acc: 0.6121\n",
            "Epoch 33/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.5542 - acc: 0.7285 - val_loss: 0.6436 - val_acc: 0.6552\n",
            "Epoch 34/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5488 - acc: 0.7209 - val_loss: 0.6400 - val_acc: 0.6724\n",
            "Epoch 35/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.5508 - acc: 0.7377 - val_loss: 0.6634 - val_acc: 0.6552\n",
            "Epoch 36/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5438 - acc: 0.7408 - val_loss: 0.6364 - val_acc: 0.6810\n",
            "Epoch 37/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.5646 - acc: 0.7209 - val_loss: 0.6067 - val_acc: 0.6983\n",
            "Epoch 38/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5599 - acc: 0.7270 - val_loss: 0.6055 - val_acc: 0.7069\n",
            "Epoch 39/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5375 - acc: 0.7408 - val_loss: 0.6065 - val_acc: 0.7155\n",
            "Epoch 40/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.5416 - acc: 0.7270 - val_loss: 0.6054 - val_acc: 0.6897\n",
            "Epoch 41/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5276 - acc: 0.7331 - val_loss: 0.6198 - val_acc: 0.6638\n",
            "Epoch 42/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5197 - acc: 0.7561 - val_loss: 0.5919 - val_acc: 0.7069\n",
            "Epoch 43/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.5373 - acc: 0.7239 - val_loss: 0.5941 - val_acc: 0.7241\n",
            "Epoch 44/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5332 - acc: 0.7377 - val_loss: 0.5847 - val_acc: 0.7155\n",
            "Epoch 45/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.5503 - acc: 0.7055 - val_loss: 0.5956 - val_acc: 0.7241\n",
            "Epoch 46/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5324 - acc: 0.7423 - val_loss: 0.7131 - val_acc: 0.6724\n",
            "Epoch 47/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5277 - acc: 0.7423 - val_loss: 0.6915 - val_acc: 0.6552\n",
            "Epoch 48/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.5417 - acc: 0.7285 - val_loss: 0.6299 - val_acc: 0.6897\n",
            "Epoch 49/300\n",
            "652/652 [==============================] - 0s 113us/step - loss: 0.5452 - acc: 0.7117 - val_loss: 0.5853 - val_acc: 0.7241\n",
            "Epoch 50/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5384 - acc: 0.7469 - val_loss: 0.6192 - val_acc: 0.6983\n",
            "Epoch 51/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5282 - acc: 0.7454 - val_loss: 0.6277 - val_acc: 0.6724\n",
            "Epoch 52/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5297 - acc: 0.7316 - val_loss: 0.6185 - val_acc: 0.7155\n",
            "Epoch 53/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.5188 - acc: 0.7377 - val_loss: 0.6144 - val_acc: 0.7155\n",
            "Epoch 54/300\n",
            "652/652 [==============================] - 0s 113us/step - loss: 0.5243 - acc: 0.7485 - val_loss: 0.6104 - val_acc: 0.6897\n",
            "Epoch 55/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.5219 - acc: 0.7362 - val_loss: 0.5875 - val_acc: 0.7241\n",
            "Epoch 56/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.5205 - acc: 0.7331 - val_loss: 0.6741 - val_acc: 0.6724\n",
            "Epoch 57/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5262 - acc: 0.7377 - val_loss: 0.5650 - val_acc: 0.7328\n",
            "Epoch 58/300\n",
            "652/652 [==============================] - 0s 135us/step - loss: 0.5393 - acc: 0.7163 - val_loss: 0.7327 - val_acc: 0.6810\n",
            "Epoch 59/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.5278 - acc: 0.7377 - val_loss: 0.6454 - val_acc: 0.6810\n",
            "Epoch 60/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.5368 - acc: 0.7301 - val_loss: 0.5936 - val_acc: 0.6724\n",
            "Epoch 61/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5220 - acc: 0.7301 - val_loss: 0.5733 - val_acc: 0.7586\n",
            "Epoch 62/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5176 - acc: 0.7515 - val_loss: 0.5658 - val_acc: 0.7586\n",
            "Epoch 63/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.5273 - acc: 0.7393 - val_loss: 0.5704 - val_acc: 0.7586\n",
            "Epoch 64/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5282 - acc: 0.7255 - val_loss: 0.6167 - val_acc: 0.6810\n",
            "Epoch 65/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.5085 - acc: 0.7469 - val_loss: 0.5709 - val_acc: 0.7500\n",
            "Epoch 66/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5127 - acc: 0.7408 - val_loss: 0.6148 - val_acc: 0.6983\n",
            "Epoch 67/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.5126 - acc: 0.7546 - val_loss: 0.5989 - val_acc: 0.7069\n",
            "Epoch 68/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5192 - acc: 0.7423 - val_loss: 0.5674 - val_acc: 0.7414\n",
            "Epoch 69/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5100 - acc: 0.7500 - val_loss: 0.6922 - val_acc: 0.6466\n",
            "Epoch 70/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.5306 - acc: 0.7393 - val_loss: 0.5637 - val_acc: 0.7414\n",
            "Epoch 71/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4985 - acc: 0.7515 - val_loss: 0.5853 - val_acc: 0.7241\n",
            "Epoch 72/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.5062 - acc: 0.7561 - val_loss: 0.5668 - val_acc: 0.7500\n",
            "Epoch 73/300\n",
            "652/652 [==============================] - 0s 127us/step - loss: 0.5126 - acc: 0.7500 - val_loss: 0.5545 - val_acc: 0.7414\n",
            "Epoch 74/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5174 - acc: 0.7469 - val_loss: 0.5600 - val_acc: 0.7759\n",
            "Epoch 75/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5390 - acc: 0.7500 - val_loss: 0.5698 - val_acc: 0.7672\n",
            "Epoch 76/300\n",
            "652/652 [==============================] - 0s 144us/step - loss: 0.5198 - acc: 0.7423 - val_loss: 0.5788 - val_acc: 0.7155\n",
            "Epoch 77/300\n",
            "652/652 [==============================] - 0s 128us/step - loss: 0.4989 - acc: 0.7592 - val_loss: 0.5601 - val_acc: 0.7672\n",
            "Epoch 78/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.5070 - acc: 0.7485 - val_loss: 0.5566 - val_acc: 0.7414\n",
            "Epoch 79/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.5043 - acc: 0.7423 - val_loss: 0.6066 - val_acc: 0.7069\n",
            "Epoch 80/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4910 - acc: 0.7561 - val_loss: 0.5804 - val_acc: 0.7155\n",
            "Epoch 81/300\n",
            "652/652 [==============================] - 0s 129us/step - loss: 0.5114 - acc: 0.7500 - val_loss: 0.5792 - val_acc: 0.7155\n",
            "Epoch 82/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.5173 - acc: 0.7561 - val_loss: 0.5961 - val_acc: 0.6983\n",
            "Epoch 83/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4937 - acc: 0.7577 - val_loss: 0.6085 - val_acc: 0.6897\n",
            "Epoch 84/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4924 - acc: 0.7807 - val_loss: 0.5912 - val_acc: 0.7328\n",
            "Epoch 85/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4994 - acc: 0.7531 - val_loss: 0.5809 - val_acc: 0.7586\n",
            "Epoch 86/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5053 - acc: 0.7485 - val_loss: 0.6628 - val_acc: 0.6379\n",
            "Epoch 87/300\n",
            "652/652 [==============================] - 0s 133us/step - loss: 0.5247 - acc: 0.7423 - val_loss: 0.5488 - val_acc: 0.7672\n",
            "Epoch 88/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.5114 - acc: 0.7577 - val_loss: 0.5498 - val_acc: 0.7586\n",
            "Epoch 89/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4907 - acc: 0.7684 - val_loss: 0.5478 - val_acc: 0.7672\n",
            "Epoch 90/300\n",
            "652/652 [==============================] - 0s 127us/step - loss: 0.5136 - acc: 0.7592 - val_loss: 0.5561 - val_acc: 0.8017\n",
            "Epoch 91/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4951 - acc: 0.7531 - val_loss: 0.5441 - val_acc: 0.7759\n",
            "Epoch 92/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.5031 - acc: 0.7377 - val_loss: 0.5687 - val_acc: 0.7155\n",
            "Epoch 93/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.5095 - acc: 0.7531 - val_loss: 0.5659 - val_acc: 0.7845\n",
            "Epoch 94/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4971 - acc: 0.7454 - val_loss: 0.5852 - val_acc: 0.6983\n",
            "Epoch 95/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.4947 - acc: 0.7592 - val_loss: 0.5889 - val_acc: 0.7069\n",
            "Epoch 96/300\n",
            "652/652 [==============================] - 0s 127us/step - loss: 0.5062 - acc: 0.7592 - val_loss: 0.5388 - val_acc: 0.7672\n",
            "Epoch 97/300\n",
            "652/652 [==============================] - 0s 113us/step - loss: 0.4960 - acc: 0.7715 - val_loss: 0.5637 - val_acc: 0.7500\n",
            "Epoch 98/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4973 - acc: 0.7623 - val_loss: 0.5858 - val_acc: 0.7414\n",
            "Epoch 99/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4933 - acc: 0.7546 - val_loss: 0.6148 - val_acc: 0.6810\n",
            "Epoch 100/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.5001 - acc: 0.7638 - val_loss: 0.6390 - val_acc: 0.6897\n",
            "Epoch 101/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4883 - acc: 0.7623 - val_loss: 0.5482 - val_acc: 0.7586\n",
            "Epoch 102/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4907 - acc: 0.7669 - val_loss: 0.5552 - val_acc: 0.7328\n",
            "Epoch 103/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.4917 - acc: 0.7577 - val_loss: 0.5837 - val_acc: 0.7069\n",
            "Epoch 104/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4806 - acc: 0.7623 - val_loss: 0.6299 - val_acc: 0.6466\n",
            "Epoch 105/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5051 - acc: 0.7546 - val_loss: 0.5860 - val_acc: 0.7155\n",
            "Epoch 106/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4947 - acc: 0.7684 - val_loss: 0.5490 - val_acc: 0.7845\n",
            "Epoch 107/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4876 - acc: 0.7653 - val_loss: 0.5375 - val_acc: 0.7586\n",
            "Epoch 108/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5190 - acc: 0.7469 - val_loss: 0.6554 - val_acc: 0.6724\n",
            "Epoch 109/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4786 - acc: 0.7699 - val_loss: 0.5781 - val_acc: 0.7069\n",
            "Epoch 110/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.5033 - acc: 0.7546 - val_loss: 0.6426 - val_acc: 0.6724\n",
            "Epoch 111/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4818 - acc: 0.7577 - val_loss: 0.5454 - val_acc: 0.7414\n",
            "Epoch 112/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4824 - acc: 0.7546 - val_loss: 0.5591 - val_acc: 0.7328\n",
            "Epoch 113/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4795 - acc: 0.7807 - val_loss: 0.5724 - val_acc: 0.7155\n",
            "Epoch 114/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4995 - acc: 0.7454 - val_loss: 0.5747 - val_acc: 0.7414\n",
            "Epoch 115/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4968 - acc: 0.7500 - val_loss: 0.5536 - val_acc: 0.7500\n",
            "Epoch 116/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4821 - acc: 0.7607 - val_loss: 0.5465 - val_acc: 0.7931\n",
            "Epoch 117/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4726 - acc: 0.7699 - val_loss: 0.5705 - val_acc: 0.7155\n",
            "Epoch 118/300\n",
            "652/652 [==============================] - 0s 126us/step - loss: 0.4814 - acc: 0.7607 - val_loss: 0.5495 - val_acc: 0.7155\n",
            "Epoch 119/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4686 - acc: 0.7791 - val_loss: 0.5406 - val_acc: 0.7672\n",
            "Epoch 120/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4821 - acc: 0.7669 - val_loss: 0.5392 - val_acc: 0.7672\n",
            "Epoch 121/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4734 - acc: 0.7761 - val_loss: 0.5574 - val_acc: 0.7586\n",
            "Epoch 122/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4866 - acc: 0.7531 - val_loss: 0.5443 - val_acc: 0.7586\n",
            "Epoch 123/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4845 - acc: 0.7761 - val_loss: 0.5548 - val_acc: 0.7586\n",
            "Epoch 124/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4757 - acc: 0.7669 - val_loss: 0.5864 - val_acc: 0.6897\n",
            "Epoch 125/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4712 - acc: 0.7669 - val_loss: 0.5635 - val_acc: 0.7241\n",
            "Epoch 126/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4841 - acc: 0.7638 - val_loss: 0.5618 - val_acc: 0.7155\n",
            "Epoch 127/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4696 - acc: 0.7730 - val_loss: 0.5451 - val_acc: 0.7931\n",
            "Epoch 128/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4831 - acc: 0.7684 - val_loss: 0.5426 - val_acc: 0.7845\n",
            "Epoch 129/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4812 - acc: 0.7745 - val_loss: 0.5440 - val_acc: 0.7759\n",
            "Epoch 130/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4679 - acc: 0.7761 - val_loss: 0.5398 - val_acc: 0.7672\n",
            "Epoch 131/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4785 - acc: 0.7623 - val_loss: 0.5375 - val_acc: 0.7759\n",
            "Epoch 132/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4651 - acc: 0.7715 - val_loss: 0.5483 - val_acc: 0.7500\n",
            "Epoch 133/300\n",
            "652/652 [==============================] - 0s 112us/step - loss: 0.4762 - acc: 0.7837 - val_loss: 0.6110 - val_acc: 0.6724\n",
            "Epoch 134/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4946 - acc: 0.7638 - val_loss: 0.5820 - val_acc: 0.7155\n",
            "Epoch 135/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4732 - acc: 0.7761 - val_loss: 0.5615 - val_acc: 0.7586\n",
            "Epoch 136/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4809 - acc: 0.7546 - val_loss: 0.5373 - val_acc: 0.7931\n",
            "Epoch 137/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4886 - acc: 0.7577 - val_loss: 0.5808 - val_acc: 0.7155\n",
            "Epoch 138/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.4675 - acc: 0.7822 - val_loss: 0.5414 - val_acc: 0.7672\n",
            "Epoch 139/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4673 - acc: 0.7699 - val_loss: 0.6026 - val_acc: 0.7069\n",
            "Epoch 140/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4820 - acc: 0.7607 - val_loss: 0.5389 - val_acc: 0.7672\n",
            "Epoch 141/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4774 - acc: 0.7638 - val_loss: 0.5494 - val_acc: 0.7414\n",
            "Epoch 142/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4817 - acc: 0.7715 - val_loss: 0.5446 - val_acc: 0.7586\n",
            "Epoch 143/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4849 - acc: 0.7469 - val_loss: 0.5381 - val_acc: 0.7759\n",
            "Epoch 144/300\n",
            "652/652 [==============================] - 0s 137us/step - loss: 0.4653 - acc: 0.7791 - val_loss: 0.5913 - val_acc: 0.7155\n",
            "Epoch 145/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4659 - acc: 0.7653 - val_loss: 0.5542 - val_acc: 0.7672\n",
            "Epoch 146/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4712 - acc: 0.7669 - val_loss: 0.5303 - val_acc: 0.7845\n",
            "Epoch 147/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4635 - acc: 0.7837 - val_loss: 0.5567 - val_acc: 0.7672\n",
            "Epoch 148/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4818 - acc: 0.7592 - val_loss: 0.5515 - val_acc: 0.7500\n",
            "Epoch 149/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4651 - acc: 0.7868 - val_loss: 0.5460 - val_acc: 0.7672\n",
            "Epoch 150/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4628 - acc: 0.7837 - val_loss: 0.5476 - val_acc: 0.7241\n",
            "Epoch 151/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.4591 - acc: 0.7822 - val_loss: 0.5787 - val_acc: 0.7241\n",
            "Epoch 152/300\n",
            "652/652 [==============================] - 0s 113us/step - loss: 0.4748 - acc: 0.7684 - val_loss: 0.6169 - val_acc: 0.6897\n",
            "Epoch 153/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4544 - acc: 0.7853 - val_loss: 0.5812 - val_acc: 0.7069\n",
            "Epoch 154/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4745 - acc: 0.7791 - val_loss: 0.5503 - val_acc: 0.7414\n",
            "Epoch 155/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4783 - acc: 0.7638 - val_loss: 0.5429 - val_acc: 0.7586\n",
            "Epoch 156/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4720 - acc: 0.7592 - val_loss: 0.5462 - val_acc: 0.7586\n",
            "Epoch 157/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4589 - acc: 0.7807 - val_loss: 0.5408 - val_acc: 0.7586\n",
            "Epoch 158/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4845 - acc: 0.7546 - val_loss: 0.5488 - val_acc: 0.7155\n",
            "Epoch 159/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4571 - acc: 0.7791 - val_loss: 0.5724 - val_acc: 0.7672\n",
            "Epoch 160/300\n",
            "652/652 [==============================] - 0s 113us/step - loss: 0.4744 - acc: 0.7899 - val_loss: 0.6475 - val_acc: 0.6810\n",
            "Epoch 161/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.4764 - acc: 0.7684 - val_loss: 0.5323 - val_acc: 0.7759\n",
            "Epoch 162/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4654 - acc: 0.7730 - val_loss: 0.5900 - val_acc: 0.6983\n",
            "Epoch 163/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4542 - acc: 0.7745 - val_loss: 0.5413 - val_acc: 0.7672\n",
            "Epoch 164/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4649 - acc: 0.7868 - val_loss: 0.5453 - val_acc: 0.7672\n",
            "Epoch 165/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4572 - acc: 0.7807 - val_loss: 0.5399 - val_acc: 0.7586\n",
            "Epoch 166/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4558 - acc: 0.7837 - val_loss: 0.6131 - val_acc: 0.6897\n",
            "Epoch 167/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4637 - acc: 0.7653 - val_loss: 0.5844 - val_acc: 0.7069\n",
            "Epoch 168/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4677 - acc: 0.7868 - val_loss: 0.5256 - val_acc: 0.7759\n",
            "Epoch 169/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4556 - acc: 0.7883 - val_loss: 0.5813 - val_acc: 0.7155\n",
            "Epoch 170/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4630 - acc: 0.7853 - val_loss: 0.5416 - val_acc: 0.7328\n",
            "Epoch 171/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4647 - acc: 0.7638 - val_loss: 0.5356 - val_acc: 0.7759\n",
            "Epoch 172/300\n",
            "652/652 [==============================] - 0s 126us/step - loss: 0.4603 - acc: 0.7914 - val_loss: 0.5491 - val_acc: 0.7500\n",
            "Epoch 173/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4514 - acc: 0.7807 - val_loss: 0.5574 - val_acc: 0.7759\n",
            "Epoch 174/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4764 - acc: 0.7822 - val_loss: 0.5653 - val_acc: 0.7241\n",
            "Epoch 175/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4611 - acc: 0.7745 - val_loss: 0.5508 - val_acc: 0.7672\n",
            "Epoch 176/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4694 - acc: 0.7761 - val_loss: 0.5947 - val_acc: 0.6810\n",
            "Epoch 177/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4609 - acc: 0.7745 - val_loss: 0.5556 - val_acc: 0.7155\n",
            "Epoch 178/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4743 - acc: 0.7730 - val_loss: 0.5461 - val_acc: 0.7328\n",
            "Epoch 179/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4633 - acc: 0.7761 - val_loss: 0.5356 - val_acc: 0.7759\n",
            "Epoch 180/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.4492 - acc: 0.8006 - val_loss: 0.5438 - val_acc: 0.7759\n",
            "Epoch 181/300\n",
            "652/652 [==============================] - 0s 169us/step - loss: 0.4602 - acc: 0.7914 - val_loss: 0.5367 - val_acc: 0.7586\n",
            "Epoch 182/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4538 - acc: 0.8006 - val_loss: 0.5568 - val_acc: 0.7155\n",
            "Epoch 183/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4549 - acc: 0.7791 - val_loss: 0.5300 - val_acc: 0.7759\n",
            "Epoch 184/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4646 - acc: 0.7837 - val_loss: 0.5264 - val_acc: 0.7672\n",
            "Epoch 185/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4611 - acc: 0.7868 - val_loss: 0.6012 - val_acc: 0.6810\n",
            "Epoch 186/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4565 - acc: 0.7868 - val_loss: 0.5368 - val_acc: 0.7414\n",
            "Epoch 187/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4472 - acc: 0.7883 - val_loss: 0.5331 - val_acc: 0.8017\n",
            "Epoch 188/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4506 - acc: 0.7822 - val_loss: 0.5521 - val_acc: 0.7328\n",
            "Epoch 189/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4661 - acc: 0.7822 - val_loss: 0.5400 - val_acc: 0.7672\n",
            "Epoch 190/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4643 - acc: 0.7853 - val_loss: 0.5268 - val_acc: 0.7845\n",
            "Epoch 191/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4534 - acc: 0.7822 - val_loss: 0.5387 - val_acc: 0.7586\n",
            "Epoch 192/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.4473 - acc: 0.7868 - val_loss: 0.5283 - val_acc: 0.7931\n",
            "Epoch 193/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4549 - acc: 0.7914 - val_loss: 0.5466 - val_acc: 0.7500\n",
            "Epoch 194/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4600 - acc: 0.7929 - val_loss: 0.5478 - val_acc: 0.7414\n",
            "Epoch 195/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.4431 - acc: 0.7929 - val_loss: 0.5302 - val_acc: 0.7845\n",
            "Epoch 196/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4433 - acc: 0.7883 - val_loss: 0.5281 - val_acc: 0.7672\n",
            "Epoch 197/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4689 - acc: 0.7761 - val_loss: 0.5492 - val_acc: 0.7069\n",
            "Epoch 198/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4552 - acc: 0.7883 - val_loss: 0.5413 - val_acc: 0.7672\n",
            "Epoch 199/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.4446 - acc: 0.7868 - val_loss: 0.5359 - val_acc: 0.7586\n",
            "Epoch 200/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.4422 - acc: 0.7929 - val_loss: 0.5288 - val_acc: 0.7845\n",
            "Epoch 201/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.4428 - acc: 0.7991 - val_loss: 0.5628 - val_acc: 0.7241\n",
            "Epoch 202/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4493 - acc: 0.7837 - val_loss: 0.5268 - val_acc: 0.7931\n",
            "Epoch 203/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4751 - acc: 0.7822 - val_loss: 0.5244 - val_acc: 0.7672\n",
            "Epoch 204/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4600 - acc: 0.7868 - val_loss: 0.5867 - val_acc: 0.7241\n",
            "Epoch 205/300\n",
            "652/652 [==============================] - 0s 146us/step - loss: 0.4823 - acc: 0.7730 - val_loss: 0.5211 - val_acc: 0.7586\n",
            "Epoch 206/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.4555 - acc: 0.7868 - val_loss: 0.5752 - val_acc: 0.7155\n",
            "Epoch 207/300\n",
            "652/652 [==============================] - 0s 129us/step - loss: 0.4567 - acc: 0.7807 - val_loss: 0.5294 - val_acc: 0.7845\n",
            "Epoch 208/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4549 - acc: 0.7929 - val_loss: 0.5399 - val_acc: 0.7328\n",
            "Epoch 209/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4499 - acc: 0.7807 - val_loss: 0.5409 - val_acc: 0.7414\n",
            "Epoch 210/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.4561 - acc: 0.7883 - val_loss: 0.5354 - val_acc: 0.7672\n",
            "Epoch 211/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4602 - acc: 0.7791 - val_loss: 0.5285 - val_acc: 0.7672\n",
            "Epoch 212/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.4530 - acc: 0.7837 - val_loss: 0.5365 - val_acc: 0.7414\n",
            "Epoch 213/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4414 - acc: 0.8052 - val_loss: 0.5350 - val_acc: 0.7586\n",
            "Epoch 214/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.4525 - acc: 0.7914 - val_loss: 0.5309 - val_acc: 0.7931\n",
            "Epoch 215/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4501 - acc: 0.7883 - val_loss: 0.5247 - val_acc: 0.7931\n",
            "Epoch 216/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4512 - acc: 0.7776 - val_loss: 0.5403 - val_acc: 0.7672\n",
            "Epoch 217/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4578 - acc: 0.7868 - val_loss: 0.5397 - val_acc: 0.7845\n",
            "Epoch 218/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4457 - acc: 0.7914 - val_loss: 0.5570 - val_acc: 0.7586\n",
            "Epoch 219/300\n",
            "652/652 [==============================] - 0s 134us/step - loss: 0.4516 - acc: 0.7730 - val_loss: 0.5497 - val_acc: 0.7328\n",
            "Epoch 220/300\n",
            "652/652 [==============================] - 0s 126us/step - loss: 0.4330 - acc: 0.8067 - val_loss: 0.5310 - val_acc: 0.7759\n",
            "Epoch 221/300\n",
            "652/652 [==============================] - 0s 137us/step - loss: 0.4326 - acc: 0.8037 - val_loss: 0.5637 - val_acc: 0.7328\n",
            "Epoch 222/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4475 - acc: 0.8006 - val_loss: 0.5484 - val_acc: 0.7328\n",
            "Epoch 223/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4422 - acc: 0.7960 - val_loss: 0.5383 - val_acc: 0.7586\n",
            "Epoch 224/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4501 - acc: 0.7975 - val_loss: 0.5588 - val_acc: 0.7241\n",
            "Epoch 225/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4531 - acc: 0.7730 - val_loss: 0.5416 - val_acc: 0.7672\n",
            "Epoch 226/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4475 - acc: 0.7914 - val_loss: 0.5545 - val_acc: 0.7414\n",
            "Epoch 227/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4440 - acc: 0.8037 - val_loss: 0.5588 - val_acc: 0.7241\n",
            "Epoch 228/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4423 - acc: 0.7883 - val_loss: 0.5289 - val_acc: 0.7586\n",
            "Epoch 229/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4430 - acc: 0.7914 - val_loss: 0.5553 - val_acc: 0.7241\n",
            "Epoch 230/300\n",
            "652/652 [==============================] - 0s 127us/step - loss: 0.4402 - acc: 0.7945 - val_loss: 0.5647 - val_acc: 0.7241\n",
            "Epoch 231/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4541 - acc: 0.7914 - val_loss: 0.5449 - val_acc: 0.7414\n",
            "Epoch 232/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4354 - acc: 0.7960 - val_loss: 0.5401 - val_acc: 0.7586\n",
            "Epoch 233/300\n",
            "652/652 [==============================] - 0s 145us/step - loss: 0.4549 - acc: 0.7837 - val_loss: 0.5331 - val_acc: 0.7845\n",
            "Epoch 234/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.4523 - acc: 0.7883 - val_loss: 0.5558 - val_acc: 0.7241\n",
            "Epoch 235/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4352 - acc: 0.7929 - val_loss: 0.5303 - val_acc: 0.7672\n",
            "Epoch 236/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.4606 - acc: 0.7791 - val_loss: 0.5512 - val_acc: 0.7328\n",
            "Epoch 237/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.4565 - acc: 0.8052 - val_loss: 0.5477 - val_acc: 0.7414\n",
            "Epoch 238/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4411 - acc: 0.7853 - val_loss: 0.5318 - val_acc: 0.7845\n",
            "Epoch 239/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4372 - acc: 0.7991 - val_loss: 0.5457 - val_acc: 0.7759\n",
            "Epoch 240/300\n",
            "652/652 [==============================] - 0s 111us/step - loss: 0.4433 - acc: 0.7868 - val_loss: 0.5287 - val_acc: 0.7672\n",
            "Epoch 241/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4322 - acc: 0.8037 - val_loss: 0.5217 - val_acc: 0.7500\n",
            "Epoch 242/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.4428 - acc: 0.7960 - val_loss: 0.5274 - val_acc: 0.7586\n",
            "Epoch 243/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4341 - acc: 0.7960 - val_loss: 0.5328 - val_acc: 0.7931\n",
            "Epoch 244/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4505 - acc: 0.7761 - val_loss: 0.5348 - val_acc: 0.7845\n",
            "Epoch 245/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4531 - acc: 0.7914 - val_loss: 0.5448 - val_acc: 0.7759\n",
            "Epoch 246/300\n",
            "652/652 [==============================] - 0s 131us/step - loss: 0.4386 - acc: 0.7945 - val_loss: 0.5522 - val_acc: 0.7414\n",
            "Epoch 247/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.4394 - acc: 0.7868 - val_loss: 0.5335 - val_acc: 0.7759\n",
            "Epoch 248/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4525 - acc: 0.7991 - val_loss: 0.5232 - val_acc: 0.7759\n",
            "Epoch 249/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4556 - acc: 0.7868 - val_loss: 0.5660 - val_acc: 0.7241\n",
            "Epoch 250/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4393 - acc: 0.7807 - val_loss: 0.5272 - val_acc: 0.7672\n",
            "Epoch 251/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4400 - acc: 0.7945 - val_loss: 0.5457 - val_acc: 0.7414\n",
            "Epoch 252/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4496 - acc: 0.7991 - val_loss: 0.5329 - val_acc: 0.7414\n",
            "Epoch 253/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4373 - acc: 0.7914 - val_loss: 0.5269 - val_acc: 0.7586\n",
            "Epoch 254/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.4383 - acc: 0.8037 - val_loss: 0.5336 - val_acc: 0.7586\n",
            "Epoch 255/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4499 - acc: 0.7883 - val_loss: 0.5300 - val_acc: 0.7586\n",
            "Epoch 256/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4303 - acc: 0.7929 - val_loss: 0.5274 - val_acc: 0.7500\n",
            "Epoch 257/300\n",
            "652/652 [==============================] - 0s 147us/step - loss: 0.4407 - acc: 0.7929 - val_loss: 0.5365 - val_acc: 0.7672\n",
            "Epoch 258/300\n",
            "652/652 [==============================] - 0s 130us/step - loss: 0.4360 - acc: 0.8052 - val_loss: 0.5773 - val_acc: 0.6983\n",
            "Epoch 259/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.4355 - acc: 0.8083 - val_loss: 0.5227 - val_acc: 0.8017\n",
            "Epoch 260/300\n",
            "652/652 [==============================] - 0s 127us/step - loss: 0.4514 - acc: 0.7822 - val_loss: 0.5402 - val_acc: 0.7586\n",
            "Epoch 261/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4436 - acc: 0.7975 - val_loss: 0.5357 - val_acc: 0.8103\n",
            "Epoch 262/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.4509 - acc: 0.7853 - val_loss: 0.5248 - val_acc: 0.7500\n",
            "Epoch 263/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4578 - acc: 0.7807 - val_loss: 0.5422 - val_acc: 0.7845\n",
            "Epoch 264/300\n",
            "652/652 [==============================] - 0s 114us/step - loss: 0.4401 - acc: 0.7945 - val_loss: 0.5199 - val_acc: 0.7759\n",
            "Epoch 265/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4574 - acc: 0.7868 - val_loss: 0.5549 - val_acc: 0.7328\n",
            "Epoch 266/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4270 - acc: 0.8083 - val_loss: 0.5719 - val_acc: 0.7069\n",
            "Epoch 267/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4395 - acc: 0.7899 - val_loss: 0.5425 - val_acc: 0.7586\n",
            "Epoch 268/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4409 - acc: 0.7960 - val_loss: 0.5637 - val_acc: 0.7241\n",
            "Epoch 269/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4453 - acc: 0.8037 - val_loss: 0.5918 - val_acc: 0.7155\n",
            "Epoch 270/300\n",
            "652/652 [==============================] - 0s 124us/step - loss: 0.4473 - acc: 0.7975 - val_loss: 0.5445 - val_acc: 0.7759\n",
            "Epoch 271/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4445 - acc: 0.7975 - val_loss: 0.5275 - val_acc: 0.7759\n",
            "Epoch 272/300\n",
            "652/652 [==============================] - 0s 123us/step - loss: 0.4295 - acc: 0.7960 - val_loss: 0.5336 - val_acc: 0.7672\n",
            "Epoch 273/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4373 - acc: 0.7807 - val_loss: 0.5597 - val_acc: 0.7241\n",
            "Epoch 274/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4395 - acc: 0.7868 - val_loss: 0.5695 - val_acc: 0.7241\n",
            "Epoch 275/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4339 - acc: 0.7975 - val_loss: 0.5503 - val_acc: 0.7328\n",
            "Epoch 276/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4307 - acc: 0.8052 - val_loss: 0.5410 - val_acc: 0.7500\n",
            "Epoch 277/300\n",
            "652/652 [==============================] - 0s 122us/step - loss: 0.4413 - acc: 0.8037 - val_loss: 0.5780 - val_acc: 0.6983\n",
            "Epoch 278/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4427 - acc: 0.7761 - val_loss: 0.5961 - val_acc: 0.7241\n",
            "Epoch 279/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4506 - acc: 0.7945 - val_loss: 0.6244 - val_acc: 0.6897\n",
            "Epoch 280/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4450 - acc: 0.7868 - val_loss: 0.5645 - val_acc: 0.7241\n",
            "Epoch 281/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4420 - acc: 0.7837 - val_loss: 0.5311 - val_acc: 0.7672\n",
            "Epoch 282/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4328 - acc: 0.7914 - val_loss: 0.5372 - val_acc: 0.7672\n",
            "Epoch 283/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4461 - acc: 0.7914 - val_loss: 0.5479 - val_acc: 0.7759\n",
            "Epoch 284/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4433 - acc: 0.7991 - val_loss: 0.5280 - val_acc: 0.7845\n",
            "Epoch 285/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4439 - acc: 0.7776 - val_loss: 0.5247 - val_acc: 0.7759\n",
            "Epoch 286/300\n",
            "652/652 [==============================] - 0s 115us/step - loss: 0.4355 - acc: 0.8037 - val_loss: 0.6777 - val_acc: 0.6810\n",
            "Epoch 287/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4293 - acc: 0.8067 - val_loss: 0.5357 - val_acc: 0.7759\n",
            "Epoch 288/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4412 - acc: 0.7868 - val_loss: 0.5422 - val_acc: 0.7672\n",
            "Epoch 289/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4348 - acc: 0.8098 - val_loss: 0.5835 - val_acc: 0.7328\n",
            "Epoch 290/300\n",
            "652/652 [==============================] - 0s 116us/step - loss: 0.4399 - acc: 0.7776 - val_loss: 0.5261 - val_acc: 0.7672\n",
            "Epoch 291/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4552 - acc: 0.7669 - val_loss: 0.5495 - val_acc: 0.8017\n",
            "Epoch 292/300\n",
            "652/652 [==============================] - 0s 119us/step - loss: 0.4420 - acc: 0.7914 - val_loss: 0.5915 - val_acc: 0.7241\n",
            "Epoch 293/300\n",
            "652/652 [==============================] - 0s 125us/step - loss: 0.4541 - acc: 0.7868 - val_loss: 0.5575 - val_acc: 0.7500\n",
            "Epoch 294/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4388 - acc: 0.7991 - val_loss: 0.5319 - val_acc: 0.7586\n",
            "Epoch 295/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4388 - acc: 0.7945 - val_loss: 0.5321 - val_acc: 0.7672\n",
            "Epoch 296/300\n",
            "652/652 [==============================] - 0s 118us/step - loss: 0.4285 - acc: 0.8067 - val_loss: 0.5345 - val_acc: 0.7500\n",
            "Epoch 297/300\n",
            "652/652 [==============================] - 0s 117us/step - loss: 0.4328 - acc: 0.7914 - val_loss: 0.5663 - val_acc: 0.7241\n",
            "Epoch 298/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4309 - acc: 0.7899 - val_loss: 0.5399 - val_acc: 0.7586\n",
            "Epoch 299/300\n",
            "652/652 [==============================] - 0s 120us/step - loss: 0.4193 - acc: 0.8113 - val_loss: 0.7281 - val_acc: 0.6638\n",
            "Epoch 300/300\n",
            "652/652 [==============================] - 0s 121us/step - loss: 0.4466 - acc: 0.7883 - val_loss: 0.5690 - val_acc: 0.7241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0afQpbJCZ5Qo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "102ca6a6-20f2-4c5f-9ec4-c3b0da752d42"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHlEBr9EZ5Qv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "478dde3e-17d3-4a8f-b1f3-310195e5c758"
      },
      "source": [
        "# Plot the History of Training Loss (history.history['loss']) and the Validation Loss (history.history['val_loss'])\n",
        "# Title should be \"Model Loss\"\n",
        "# x label: \"Loss\"\n",
        "# y label: \"Epoch\"\n",
        "# Legend: \"Train\" and \"Validation\"\n",
        "# TODO\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrssAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9vYSh0FZ5Qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c4804493-c282-4716-880f-ef62f9527eb3"
      },
      "source": [
        "# Plot the History of Training Accuracy (history.history['acc']) and \n",
        "# the Validation Accuracy (history.history['val_loss'])\n",
        "#\n",
        "# Title should be \"Model Accuracy\"\n",
        "# x label: \"Accuracy\"\n",
        "# y label: \"Epoch\"\n",
        "# Legend: \"Train\" and \"Validation\"\n",
        "# TODO\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMyvFCcPMzEpxwjAzs1L+DyZQKqPSiKwQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU6y3UaCZ5Q1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0ebaef6-aa61-49be-ab5d-a42806e721fe"
      },
      "source": [
        "# Evaluate the loss and accuracy on the test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116/116 [==============================] - 0s 72us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6dd3YjoZ5Q8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "028f05de-901e-483a-f766-0b4a1282daa1"
      },
      "source": [
        "print('Test score:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.4379977239616986\n",
            "Test accuracy: 0.7672413751996797\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}